{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 100k 전체 파이프라인 (GPU 가속)\n",
    "\n",
    "이 노트북은 100k 합성 데이터셋에 대한 전체 ML 파이프라인을 실행합니다.\n",
    "\n",
    "**전제**:\n",
    "- `data/synthetic/ml_dataset/`에 100k 데이터가 생성되어 있음\n",
    "- GPU 환경이 구성되어 있음 (`00_setup_gpu_env.ipynb` 검증 완료)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo = Path(\"../\").resolve()\n",
    "sys.path.insert(0, str(repo / \"src\"))\n",
    "\n",
    "BASE = repo / \"data\" / \"synthetic\" / \"ml_dataset\"\n",
    "manifest = BASE / \"manifest.json\"\n",
    "print(f\"Manifest exists: {manifest.exists()}\")\n",
    "if manifest.exists():\n",
    "    import json\n",
    "    m = json.loads(manifest.read_text())\n",
    "    print(f\"Total count: {m.get('total_count', 'N/A')}\")\n",
    "    print(f\"Splits: {m.get('splits', {})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 특징 추출 (병렬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motionanalyzer.auto_optimize import (\n",
    "    FeatureExtractionConfig,\n",
    "    prepare_training_data,\n",
    "    normalize_features,\n",
    ")\n",
    "import json\n",
    "\n",
    "manifest = json.loads((BASE / \"manifest.json\").read_text())\n",
    "entries = manifest[\"entries\"]\n",
    "\n",
    "normal_train = [BASE / e[\"path\"] for e in entries if e[\"goal\"] == \"normal\" and e[\"split\"] == \"train\"]\n",
    "normal_val = [BASE / e[\"path\"] for e in entries if e[\"goal\"] == \"normal\" and e[\"split\"] == \"val\"]\n",
    "normal_test = [BASE / e[\"path\"] for e in entries if e[\"goal\"] == \"normal\" and e[\"split\"] == \"test\"]\n",
    "crack_train = [BASE / e[\"path\"] for e in entries if e[\"goal\"] == \"goal1\" and e[\"split\"] == \"train\"]\n",
    "crack_val = [BASE / e[\"path\"] for e in entries if e[\"goal\"] == \"goal1\" and e[\"split\"] == \"val\"]\n",
    "crack_test = [BASE / e[\"path\"] for e in entries if e[\"goal\"] == \"goal1\" and e[\"split\"] == \"test\"]\n",
    "\n",
    "cfg = FeatureExtractionConfig(\n",
    "    include_per_frame=True,\n",
    "    include_per_point=False,\n",
    "    include_global_stats=True,\n",
    "    include_crack_risk_features=False,\n",
    "    include_advanced_stats=True,\n",
    "    include_frequency_domain=True,\n",
    ")\n",
    "\n",
    "print(\"Extracting train features...\")\n",
    "feat_train, lab_train = prepare_training_data(normal_train, crack_train, feature_config=cfg)\n",
    "print(f\"Train: {len(feat_train)} samples\")\n",
    "\n",
    "print(\"Extracting val features...\")\n",
    "feat_val, lab_val = prepare_training_data(normal_val, crack_val, feature_config=cfg)\n",
    "print(f\"Val: {len(feat_val)} samples\")\n",
    "\n",
    "print(\"Extracting test features...\")\n",
    "feat_test, lab_test = prepare_training_data(normal_test, crack_test, feature_config=cfg)\n",
    "print(f\"Test: {len(feat_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 정규화 및 DREAM/PatchCore 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "exclude = [\"label\", \"dataset_path\", \"frame\", \"index\", \"x\", \"y\"]\n",
    "feature_cols = [c for c in feat_train.columns if c not in exclude and \"crack_risk\" not in c.lower()\n",
    "                and c in feat_train.select_dtypes(include=[\"number\"]).columns]\n",
    "\n",
    "normal_mask = np.asarray(lab_train, dtype=int) == 0\n",
    "norm_train = normalize_features(feat_train, exclude_cols=exclude, fit_df=feat_train.loc[normal_mask])\n",
    "norm_val = normalize_features(feat_val, exclude_cols=exclude, fit_df=feat_train.loc[normal_mask])\n",
    "norm_test = normalize_features(feat_test, exclude_cols=exclude, fit_df=feat_train.loc[normal_mask])\n",
    "\n",
    "X_train = norm_train[feature_cols].fillna(0).to_numpy(dtype=np.float32)\n",
    "y_train = np.asarray(lab_train, dtype=int)\n",
    "X_val = norm_val[feature_cols].fillna(0).to_numpy(dtype=np.float32)\n",
    "y_val = np.asarray(lab_val, dtype=int)\n",
    "X_test = norm_test[feature_cols].fillna(0).to_numpy(dtype=np.float32)\n",
    "y_test = np.asarray(lab_test, dtype=int)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motionanalyzer.gui.runners import _run_dream, _run_patchcore\n",
    "\n",
    "def log(msg): print(msg)\n",
    "def progress(): pass\n",
    "\n",
    "print(\"Training DREAM (GPU if available)...\")\n",
    "res_dream = _run_dream(\n",
    "    pd.DataFrame(X_train, columns=feature_cols),\n",
    "    y_train,\n",
    "    log=log, progress=progress,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "print(f\"DREAM success: {res_dream.get('success')}\")\n",
    "\n",
    "print(\"Training PatchCore...\")\n",
    "res_patch = _run_patchcore(\n",
    "    pd.DataFrame(X_train, columns=feature_cols),\n",
    "    y_train,\n",
    "    log=log, progress=progress,\n",
    ")\n",
    "print(f\"PatchCore success: {res_patch.get('success')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 검증 및 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "results = {}\n",
    "\n",
    "if res_dream.get(\"success\"):\n",
    "    from motionanalyzer.ml_models.dream import DREAMPyTorch\n",
    "    model = DREAMPyTorch(input_dim=len(feature_cols))\n",
    "    model.load(res_dream[\"model_path\"])\n",
    "    scores_val = model.predict(X_val)\n",
    "    scores_test = model.predict(X_test)\n",
    "    # Threshold from val (simplified)\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    prec, rec, thresh = precision_recall_curve(y_val, scores_val)\n",
    "    best_idx = np.argmax(2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12))\n",
    "    thresh_best = float(thresh[best_idx])\n",
    "    pred = (scores_test >= thresh_best).astype(int)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    results[\"DREAM\"] = {\"cm\": cm, \"roc\": roc_auc_score(y_test, scores_test)}\n",
    "    print(\"DREAM:\", cm, \"ROC:\", results[\"DREAM\"][\"roc\"])\n",
    "\n",
    "if res_patch.get(\"success\"):\n",
    "    from motionanalyzer.ml_models.patchcore import PatchCoreScikitLearn\n",
    "    model = PatchCoreScikitLearn(feature_dim=len(feature_cols))\n",
    "    model.load(res_patch[\"model_path\"])\n",
    "    scores_val = model.predict(pd.DataFrame(X_val, columns=feature_cols))\n",
    "    scores_test = model.predict(pd.DataFrame(X_test, columns=feature_cols))\n",
    "    prec, rec, thresh = precision_recall_curve(y_val, scores_val)\n",
    "    best_idx = np.argmax(2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-12))\n",
    "    thresh_best = float(thresh[best_idx])\n",
    "    pred = (scores_test >= thresh_best).astype(int)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    results[\"PatchCore\"] = {\"cm\": cm, \"roc\": roc_auc_score(y_test, scores_test)}\n",
    "    print(\"PatchCore:\", cm, \"ROC:\", results[\"PatchCore\"][\"roc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
